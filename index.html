<!DOCTYPE HTML>
<html lang="en">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta name="author" content="Yahav Avigal">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>Yahav Avigal</title>
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/seal_icon.png">

  <link rel="preconnect" href="https://fonts.googleapis.com"> 
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin> 
  <link href="https://fonts.googleapis.com/css2?family=Lato:ital,wght@0,400;0,700;1,400&display=swap" rel="stylesheet">
</head>

<body>
  <div class="container">
    <div class="profile">
      <div>
        <h1 class="name">Yahav Avigal</h1>

        <p>
          I am a fourth year PhD student at UC Berkeley, advised by Professor <a href="https://goldberg.berkeley.edu">Ken Goldberg</a> in the <a href="https://autolab.berkeley.edy/">AUTOLab</a>.
        </p>
        <p>
          My research interests are in robotic grasping and motion planning in dynamic environments using deep learning.
          In my work I explore how to: transport objects fast without dropping or spilling their content, leverage NeRF to manipulate transparent objects, and applying dynamic motions to manipulate garments.
        </p>
        <p style="text-align:center">
          <a href="mailto:yahavigal@gmail.com">Email</a> &nbsp/&nbsp
          <a href="https://scholar.google.com/citations?user=CCAaFCQAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
          <a href="https://twitter.com/yahavigal">Twitter</a> &nbsp/&nbsp
          <a href="https://www.linkedin.com/in/yahav-avigal/">LinkedIn</a>
        </p>
      </div>

      <div class="profile-image">
        <a href="images/yahav_pic.jpg">
          <img style="max-width:100%; width:100%;" alt="profile photo" src="images/yahav_pic_circle.jpg">
        </a>
      </div>
    </div>

    <div class="topic">
      <h2 class="heading">Clothes Folding</h2>

      <div class="paper">
        <img class="paper-image" src="images/speedfolding.gif">

        <div class="paper-info">
          <div class="paper-title">
            <a href="https://pantor.github.io/speedfolding/">SpeedFolding: Learning Efficient Bimanual Folding of Garments</a>
          </div>

          <div>
            <strong>Yahav Avigal*</strong>,
            <a href="https://github.com/pantor">Lars Berscheid*</a>,
            <a href="https://h2t.anthropomatik.kit.edu/english/21_2372.php">Tamim Asfour</a>,
            <a href="https://www.ipr.kit.edu/english/staff_2538.php">Torsten Kröger</a>,
            <a href="https://goldberg.berkeley.edu/">Ken Goldberg</a>
          </div>
          <div>
            <strong>Best Paper Award</strong>
          </div>
          <div>
            <strong>RoboCup Award</strong>
          </div>

          <em>International Conference on Intelligent Robots and Systems (IROS) </em>, 2022
          <div>
            <a href="https://arxiv.org/abs/2208.10552">arXiv</a> / 
            <a href="https://www.youtube.com/watch?v=em675-X2jfM&ab_channel=Griffig">Video</a>
          </div>
          <div>
            Press:
            <a href="https://www.npr.org/2022/10/22/1130552239/robot-folding-laundry">npr</a> / 
            <a href="https://spectrum.ieee.org/robot-videos-iros-award-winners">IEEE Spectrum</a> / 
            <a href="https://arstechnica.com/information-technology/2022/10/tired-of-laundry-folding-ai-breaks-the-robot-folding-speed-record/">Ars Technica</a>
          </div> 
        </div>
      </div>
    </div>

    <div class="topic">
      <h2 class="heading">Manipulating Transparent Objects</h2>

      <div class="paper">
        <img class="paper-image" src="images/dexnerf.gif">

        <div class="paper-info">
          <div class="paper-title">
            <a href="https://sites.google.com/view/dex-nerf">Dex-NeRF: Using a Neural Radiance Field to Grasp Transparent Objects</a>
          </div>

          <div>
            <a href="https://ichnow.ski/">Jeffrey Ichnowski*</a>,
            <strong>Yahav Avigal*</strong>,
            <a href="https://kerrj.github.io/">Justin Kerr</a>,
            <a href="https://goldberg.berkeley.edu/">Ken Goldberg</a>
          </div>

          <em>Conference on Robot Learning (CoRL) </em>, 2021

          <div>
            <a href="https://arxiv.org/abs/2110.14217">arXiv</a> / 
            <a href="https://openreview.net/forum?id=zOjU2vZzhCk">OpenReview</a> /
            <a href="https://youtu.be/F9R6Nf1d7P4">Video</a> /
            <a href="https://twitter.com/yahavigal/status/1453769964582674438">Tweet</a>
          </div>

          Press: <a href="https://www.wired.com/story/new-way-ai-see-3d/">WiReD</a>
        </div>
      </div>
    </div>

    <div class="topic">
      <h2 class="heading">Grasp Optimized Motion Planning</h2>

      <div class="paper">
        <img class="paper-image" src="images/GOMP-ST.gif">

        <div class="paper-info">
          <div class="paper-title">
            <a href="https://sites.google.com/view/gomp-st/">GOMP-ST: Grasp-Optimized Motion Planning for Suction Transport</a>
          </div>

          <div>
            <strong>Yahav Avigal*</strong>,
            <a href="https://ichnow.ski/">Jeffrey Ichnowski*</a>,
            Max Cao,
            <a href="https://goldberg.berkeley.edu/">Ken Goldberg</a>
          </div>

          <em>International Workshop on the Algorithmic Foundations of Robotics (WAFR) </em>, Jun 2022 

          <div>
            <a href="https://arxiv.org/abs/2203.08359">arXiv</a>
          </div>
        </div>
      </div>

      <div class="paper">
        <img class="paper-image" src="images/GOMP-FIT.gif">

        <div class="paper-info">
          <div class="paper-title">
            <a href="https://berkeleyautomation.github.io/gomp-fit/">GOMP-FIT: Grasp-Optimized Motion Planning for Fast Inertial Transport</a>
          </div>

          <div>
            <a href="https://ichnow.ski/">Jeffrey Ichnowski</a>,
            <strong>Yahav Avigal</strong>,
            Yi Liu,
            <a href="https://goldberg.berkeley.edu/">Ken Goldberg</a>
          </div>

          <em>International Conference on Robotics and Automation (ICRA) </em>, May 2022 

          <div>
            <a href="https://arxiv.org/abs/2110.15326">arXiv</a>
          </div>
        </div>
      </div>

      <div class="paper">
        <img class="paper-image" src="images/djgomp.jpeg">

        <div class="paper-info">
          <div class="paper-title">
            <a href="https://berkeleyautomation.github.io/dj-gomp/">Deep Learning Can Accelerate Grasp-Optimized Motion Planning</a>
          </div>

          <div>
            <a href="https://ichnow.ski/">Jeffrey Ichnowski</a>,
            <strong>Yahav Avigal</strong>,
            Vishal Satish,
            <a href="https://goldberg.berkeley.edu/">Ken Goldberg</a>
          </div>

          <em>Science Robotics </em>, Nov 2020
          
          <div>
            <a href="https://www.science.org/doi/10.1126/scirobotics.abd7710">Journal</a> /
            <a href="https://goldberg.berkeley.edu/pubs/SR-DJ-GOMP-Nov-2020.pdf">PDF</a>
          </div>
          
          <div>
            Press:
            <a href="https://news.berkeley.edu/2020/11/18/deep-learning-helps-robots-grasp-and-move-objects-with-ease/">Berkeley News</a> / 
            <a href="https://www.newscientist.com/article/2260014-warehouse-robots-upgraded-to-make-packing-decisions-350-times-faster/">New Scientist</a> / 
            <a href="https://techcrunch.com/2020/11/18/interlocking-ais-let-robots-pick-and-place-faster-than-ever/">TechCrunch</a> /
            <a href="https://jp.techcrunch.com/2020/11/19/2020-11-18-interlocking-ais-let-robots-pick-and-place-faster-than-ever/">TC 日本</a> / 
            <a href="https://www.thetimes.co.uk/article/holding-on-to-job-becomes-harder-as-robots-get-a-grip-mrkhp3nsm">The Times</a> /
            <a href="https://finance.yahoo.com/news/interlocking-ais-let-robots-pick-190131191.html">Yahoo!</a> /
            <a href="https://techxplore.com/news/2020-11-deep-robots-grasp-ease.html">Tech Xplore</a> /
            <a href="https://www.miragenews.com/deep-learning-helps-robots-grasp-and-move-objects-with-ease/">Mirage</a> /
            <a href="https://www.sciencedaily.com/releases/2020/11/201118141827.htm">ScienceDaily</a> /
            <a href="https://cosmosmagazine.com/news/making-robots-useful-in-the-warehouse/">Cosmos</a> /
            <a href="https://www.analyticsinsight.net/deep-learning-will-make-robots-grasp-and-move-objects-easily/">Analytics Insight</a> /
            <a href="https://www.engineering.com/DesignSoftware/DesignSoftwareArticles/ArticleID/20996/Deep-Learning-Software-Accelerates-Robots-Ability-to-Grasp-and-Move-Objects.aspx">engineering.com</a> /
            <a href="https://www.therobotreport.com/neural-networks-plus-motion-planning-equals-more-nimble-robots-uc-berkeley/">The Robot Report</a>
          </div>
        </div>
      </div>
    </div>

    <div class="topic">
      <h2 class="heading">Autonomous Gardening</h2>

      <div class="paper">
        <img class="paper-image" src="images/garden_timelapse.gif">

        <div class="paper-info">
          <div class="paper-title">
            <a href="https://rieff.jacksonchui.ai/about">Learning Seed Placements and Automation Policies for Polyculture Farming with Companion Plants</a>
          </div>

          <div>
            <strong>Yahav Avigal</strong>,
            Jensen Gao,
            William Wong,
            Kevin Li,
            Grady Pierroz,
            Fang Shuo Deng,
            Mark Presten,
            Mark Theis,
            Jackson Chui,
            Paul Shao,
            Huang Huang,
            Atsunobu Kotani,
            Satvik Sharma,
            Rishi Parikh,
            Michael Luo,
            Sandeep Mukherjee,
            Stefano Carpin,
            Joshua H. Viers,
            Stavros Vougioukas,
            <a href="https://goldberg.berkeley.edu/">Ken Goldberg</a>
          </div>

          <em>International Conference on Robotics and Automation (ICRA)</em>, Jun 2021  

          <div>
            <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9561431">PDF</a>
          </div>
        </div>
      </div>

      <div class="paper">
        <img class="paper-image" src="images/alphagarden.jpg">

        <div class="paper-info">
          <div class="paper-title">
            <a href="https://rieff.jacksonchui.ai/about">Simulating Polyculture Farming to Learn Automation Policies for Plant Diversity and Precision Irrigation</a>
          </div>

          <div>
            <strong>Yahav Avigal</strong>,
            Jensen Gao,
            William Wong,
            Kevin Li,
            Grady Pierroz,
            Fang Shuo Deng,
            Mark Theis,
            Mark Presten,
            <a href="https://goldberg.berkeley.edu/">Ken Goldberg</a>
          </div>

          <em>Conference on Automation Science and Engineering (CASE) </em>, Aug 2020  
          
          <div>
            <strong>Best Student Paper Award</strong>
          </div>

          <div>
            <a href="https://drive.google.com/file/d/1XydQmKBNP4_r_8X2Pu1Bk2CXVNJyrJVF/view?usp=sharing">PDF</a> /
            <a href="https://parsons.edu/sheilacjohnsondesigncenter/the-question-of-intelligence-ai-and-the-future-of-humanity/">Exhibition@Parsons School of Design</a>
          </div>

          <em>Transactions on Automation Science and Engineering (TASE) </em>, Early Access  
          
          <div>
            <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9684020">PDF</a>
          </div>
        </div>
      </div>
    </div>
  </div>
</body>

</html>
